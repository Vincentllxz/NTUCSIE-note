\contentsline {chapter}{\numberline {1}Optimization Problems for Deep Learning}{2}{chapter.1}%
\contentsline {section}{\numberline {1.1}Linear Classification}{2}{section.1.1}%
\contentsline {subsection}{\numberline {1.1.1}Minimizing Training Errors}{2}{subsection.1.1.1}%
\contentsline {subsection}{\numberline {1.1.2}Loss Functions}{3}{subsection.1.1.2}%
\contentsline {subsection}{\numberline {1.1.3}Overfitting}{4}{subsection.1.1.3}%
\contentsline {subsection}{\numberline {1.1.4}Regularization}{5}{subsection.1.1.4}%
\contentsline {section}{\numberline {1.2}Fully-connected Networks}{5}{section.1.2}%
\contentsline {subsection}{\numberline {1.2.1}Multi-class Classification}{5}{subsection.1.2.1}%
\contentsline {subsection}{\numberline {1.2.2}Operation Between Layers}{6}{subsection.1.2.2}%
\contentsline {section}{\numberline {1.3}Convolutional Neural Networks}{8}{section.1.3}%
\contentsline {subsection}{\numberline {1.3.1}Convolutional Neural Networks (CNNs)}{8}{subsection.1.3.1}%
\contentsline {subsection}{\numberline {1.3.2}Convolutional Layer}{9}{subsection.1.3.2}%
\contentsline {subsection}{\numberline {1.3.3}Matrix Operations}{11}{subsection.1.3.3}%
\contentsline {subsection}{\numberline {1.3.4}Optimization Problem for CNN}{13}{subsection.1.3.4}%
\contentsline {subsection}{\numberline {1.3.5}Padding Layers}{13}{subsection.1.3.5}%
\contentsline {subsection}{\numberline {1.3.6}Pooling Layers}{14}{subsection.1.3.6}%
\contentsline {subsection}{\numberline {1.3.7}Summary of CNN Layers}{15}{subsection.1.3.7}%
\contentsline {subsection}{\numberline {1.3.8}Fully-connected Layers}{16}{subsection.1.3.8}%
\contentsline {chapter}{\numberline {2}Stochastic gradient methods for deep learning}{17}{chapter.2}%
\contentsline {section}{\numberline {2.1}Gradient Descent}{17}{section.2.1}%
\contentsline {subsection}{\numberline {2.1.1}Line Search}{18}{subsection.2.1.1}%
\contentsline {subsection}{\numberline {2.1.2}Practical Gradient Descent Algorithm}{20}{subsection.2.1.2}%
\contentsline {section}{\numberline {2.2}Stochastic Gradient Method}{20}{section.2.2}%
\contentsline {subsection}{\numberline {2.2.1}Estimation of Gradient}{20}{subsection.2.2.1}%
\contentsline {subsection}{\numberline {2.2.2}Momentum Method}{21}{subsection.2.2.2}%
\contentsline {subsection}{\numberline {2.2.3}AdaGrad (Adaptive Gradient Algorithm)}{22}{subsection.2.2.3}%
\contentsline {subsection}{\numberline {2.2.4}RMSProp (Relative Mean Square Propagation)}{23}{subsection.2.2.4}%
\contentsline {subsection}{\numberline {2.2.5}Adam (Adaptive Moment Estimation)}{23}{subsection.2.2.5}%
\contentsline {subsection}{\numberline {2.2.6}AdamW (Adam with Weight Decay)}{25}{subsection.2.2.6}%
\contentsline {subsection}{\numberline {2.2.7}Why Stochastic Gradient?}{26}{subsection.2.2.7}%
\contentsline {section}{\numberline {2.3}Convergence of Stochastic Gradient Method}{27}{section.2.3}%
\contentsline {chapter}{\numberline {3}Gradient Calculation}{31}{chapter.3}%
\contentsline {section}{\numberline {3.1}Vector Form}{31}{section.3.1}%
\contentsline {section}{\numberline {3.2}Gradient Calculation}{33}{section.3.2}%
\contentsline {subsection}{\numberline {3.2.1}Gradient Calculation for Convolution Layer}{33}{subsection.3.2.1}%
\contentsline {subsection}{\numberline {3.2.2}Gradient Calculation for Fully-connected Layer}{36}{subsection.3.2.2}%
\contentsline {chapter}{\numberline {4}Implementation}{37}{chapter.4}%
\contentsline {chapter}{\numberline {5}GPU Programming}{38}{chapter.5}%
\contentsline {chapter}{\numberline {6}Automatic Differentiation}{39}{chapter.6}%
\contentsline {section}{\numberline {6.1}Basic Concepts}{39}{section.6.1}%
\contentsline {section}{\numberline {6.2}Implementation}{39}{section.6.2}%
\contentsline {chapter}{\numberline {7}Large Language Models (LLM)}{40}{chapter.7}%
\contentsline {section}{\numberline {7.1}High-level Overview}{40}{section.7.1}%
\contentsline {section}{\numberline {7.2}Auto-regressive Models}{40}{section.7.2}%
\contentsline {section}{\numberline {7.3}Detailed Operations}{40}{section.7.3}%
