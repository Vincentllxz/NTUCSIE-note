\lecture{5}{30 Sep. 13:20}{}

\subsection{Nullspace of $A$}

\begin{definition}
    Let $\mathcal{N}(A) = \{ x \in \mathbb{R}^{\red{n}} \;|\; Ax=0 \}$, then $\mathcal{N}(A) \leq \mathbb{R}^n / \mathbb{R}$. Then $\mathcal{N}(A)$ is called the \redbox{null space} of $A$.
\end{definition}
\begin{proof}
    We proof it with the Theorem \ref{thm:2.1.1}
    \begin{itemize}
        \item zero vector is in the $\mathcal{N}(A)$
        \item $x,\ x' \in \mathcal{N}(A) \ \Rightarrow \ Ax = 0, \ Ax' = 0$
        \[
            A(x + x') = Ax + Ax' = 0 + 0 = 0 \ \Rightarrow \ x + x' \in \mathcal{N}(A)
        \]
        \[
            A(\alpha x) = \alpha A x = \alpha \cdot 0 = 0 \ \Rightarrow \ \alpha x \in \mathcal{N}(A), \forall \alpha \in \mathbb{R} \quad \therefore \mathcal{N}(A) \leq \mathbb{R}^n / \mathbb{R}
        \]
    \end{itemize}
\end{proof}

\begin{note}
The system $Ax = 0$ is called a homogeneous equation. (齊次)
\end{note}

\begin{remark}
    The solution set of $Ax = b$ \red{is NOT} a subspace of $\mathbb{R}^n / \mathbb{R}$
    \[
    x, x' \ \longrightarrow \ Ax = b, \ Ax' = b
    \]
    \[
    A(x + x') = Ax + Ax' = 2b \neq b
    \]
\end{remark}

\begin{eg}
\[
\begin{pmatrix}
    1 & 4 \\
    2 & 5 \\
    3 & 6
\end{pmatrix} \begin{pmatrix}
    u \\ v
\end{pmatrix} = \begin{pmatrix}
    0 \\ 0 \\ 0
\end{pmatrix} \quad \Longrightarrow \quad \mathcal{N}(A) = \left\{ \begin{pmatrix}
    0 \\ 0
\end{pmatrix} \right\}
\]
\end{eg}

\begin{eg}
\[
\begin{pmatrix}
    1 & 4 & 5 \\
    2 & 5 & 7 \\
    3 & 6 & 9
\end{pmatrix} \begin{pmatrix}
    u \\ v \\ w
\end{pmatrix} = \begin{pmatrix}
    0 \\ 0 \\ 0
\end{pmatrix} \quad \Longrightarrow \quad \mathcal{N}(A) = \left\{ \begin{pmatrix}
    t\\ t\\ -t
\end{pmatrix}, t \in (-\infty, \infty) \right\}
\]
\end{eg}

\begin{align*}
    \mathcal{C}(A) &= \{ \text{all combinations of columns of } A \} \\
    &= \text{ column space of }A \leq \mathbb{R}^m / \mathbb{R}
\end{align*}

\begin{align*}
    \mathcal{N}(A) &= \{ x \in \mathbb{R}^n \;|\; Ax=0 \} \\
    &= \text{ null space of }A \leq \mathbb{R}^n / \mathbb{R}
\end{align*}

\section{The Solution of $m$ Equations in $n$ Unknows}

For $ax = b, \quad a,b,x \in \mathbb{R}$

\begin{enumerate}[label=(\roman*)]
    \item if $\displaystyle a\neq 0 \ \Rightarrow \ x = \frac{b}{a}$, unique
    \item if $a = 0$, $b = 0 \ \Rightarrow \ $ infinitely many solutions.
    \item if $a = 0$, $b = 0 \ \Rightarrow \ $ no $x$ exists.
\end{enumerate}

\noindent\hrulefill

\vspace{1em}

Now, consider $Ax = b$, if $A$ is a square, then (i), (ii), (iii) may occur.

\begin{enumerate}[label=(\roman*)]
    \item $A^{-1}$ exists $\longrightarrow \ x = A^{-1} b$, unique
    \item $A$ is singular (undetermined case)
    \item inconsistent case.
\end{enumerate}

\noindent\hrulefill

\vspace{1em}

With a rectangular matrix $A$, $x = A^{-1}b $ \blue{will never happen!}

\newpage

\begin{definition*}
    Here is the definition of two similar jargon.
    \begin{definition}[row echelon matrix]
        An $m \times n$ matrix $R$ is called a \redbox{row echelon matrix} if 
        \begin{enumerate}[label=(\roman*)]
            \item the nonzero rows come first and the pivots are the first nonzero etries in those rows.
            \item below each pivot is a column of zeros
            \item each pivot lies to the right of the pivot in the row above.
        \end{enumerate}
        e.g.
        \[
            \begin{pmatrix}
            \circledast & \circledast & \circledast & \circledast & \circledast\\
            0           & \circledast & \circledast & \circledast & 0\\
            0           & 0           & 0           & \circledast & \circledast
            \end{pmatrix}
        \]

    \end{definition}

    \begin{definition}[row-reduced echelon matrix]
        An $m \times n$ matrix $R$ is called a \redbox{row-reduced} \redbox{echelon matrix} if 
        \begin{enumerate}[label=(\roman*)]
            \item the nonzero rows come first and the pivots are the first nonzero etries in those rows; \blue{pivots are normalized to be $1$}.
            \item \blue{Above \& Below} each pivot is a column of zeros
            \item each pivot lies to the right of the pivot in the row above.
        \end{enumerate}
        e.g.
        \[
            \begin{pmatrix}
            \redbox{1} & 0 & \circledast & 0 & \circledast\\
            0 & \redbox{1} & \circledast & 0 & \circledast\\
            0 & 0 & 0 & \redbox{1} & \circledast
            \end{pmatrix}
        \]
    \end{definition}
\end{definition*}

\begin{theorem}
    To any $m \times n$ matrix $A$, there exists a permutation matrix $P$, a lower triangular matrix $L$ with unit diagnal and an $m \times n$ echelon matrix $U \ni PA = LU$ \\
    \textbf{OR} \\
    Every $m \times n$ matrix $A$ is \red{row equivalent to} a row echelon matrix.
\end{theorem}

\newpage

\begin{itemize}
    \item \blue{Case 1. Homogeneous Case. $b_{m \times 1} = 0$}
    
    \[
    Ax = 0
    \]
    
    We call the component of $x$ , which correspond to columns with pivots the \red{basic variables}; and these correspond to columns with pivots the \red{free variables}.
    
    \[
    \begin{pmatrix}
        \redbox{1} & 3 & 3 & 2 \\
        0 & 0 & \redbox{3} & 1 \\
        0 & 0 & 0 & 0
    \end{pmatrix} \begin{pmatrix}
        u \\ v \\ w \\ y
    \end{pmatrix} = \begin{pmatrix}
        0 \\ 0 \\ 0
    \end{pmatrix}, \quad \begin{cases}
        \text{basic variables: } u, w \\
        \text{free variables: } v, y
    \end{cases}
    \]
    The basic variables are then expressed in terms of free variables.
    \[
    \begin{cases}
        3w + y = 0 \\
        u + 3v + 3w + 2y = 0
    \end{cases} \quad \Longrightarrow \quad \begin{cases}
        w = -\frac{1}{3} y \\
        u = -3v - y
    \end{cases}
    \]
    \[
    x = \begin{pmatrix}
        u \\ v \\ w \\ y
    \end{pmatrix} = \begin{pmatrix}
        -3v-y \\ v \\ -\frac{1}{3}y \\ y
    \end{pmatrix} = v\begin{pmatrix}
        -3 \\ 1 \\ 0 \\ 0
    \end{pmatrix} + y \begin{pmatrix}
        -1 \\ 0 \\ -\frac{1}{3} \\ 1
    \end{pmatrix}
    \]


    \begin{itemize}
        \item 
        \(
        \begin{pmatrix}
            -3 \\ 1 \\ 0 \\ 0
        \end{pmatrix}
        \) is obtain from $x$ by setting \(
        \begin{cases}
        v = 1 \\
        y = 0
        \end{cases}
        \)
        \item 
        \(
        \begin{pmatrix}
            1 \\ 0 \\ -\frac{1}{3} \\ 0
        \end{pmatrix}
        \) is obtain from $x$ by setting \(
        \begin{cases}
        v = 0 \\
        y = 1
        \end{cases}
        \)
    \end{itemize}

    \begin{theorem}
        If a homogeneous system $A_{m \times n}x = 0$ has more $\overset{n}{\text{unknows}}$ than $\overset{m}{\text{equations}}$ (m \blue{<} n), it has a nontrivial solution.
        \[
        (A_{m \times n}) \ \longrightarrow \ (A_{m \times n})
        \]
        at most $m$ pivot, at most $m$ basic variables, at least $(n-m)$ free variables.
    \end{theorem}

    \begin{note}
    The nullspace is a subspace of the same \redbox{dimension} as the number of \redbox{free} variables.
    \end{note}

    \newpage

    \item \blue{Case 2. Inhomogeneous Case: $b \neq 0$}
    \[
    Ax = b \ \rightarrow \ Ux = c \ \text{where} \ c = L^{-1}b
    \]

    \[
    \begin{pmatrix}
        1 & 3 & 3 & 2 \\
        2 & 6 & 9 & 5 \\
        -1 & -3 & 3 & 0
    \end{pmatrix} \begin{pmatrix}
        x_1 \\ x_2 \\ x_3 \\ x_4
    \end{pmatrix} = \begin{pmatrix}
        b_1 \\ b_2 \\ b_3
    \end{pmatrix}
    \]
    \[
    \Longrightarrow \quad \begin{pmatrix}
        \redbox{1} & 3 & 3 & 2 \\
        0 & 0 & \redbox{3} & 1 \\
        0 & 0 & 0 & 0
    \end{pmatrix} \begin{pmatrix}
        u \\ v \\ w \\ y
    \end{pmatrix} = \begin{pmatrix}
        b_1 \\ b_2 - 2b_1 \\ b_3 - 2b_2 + 5b_1
    \end{pmatrix} \quad \longrightarrow \quad b_3 - 2b_2 + 5b_1 = 0
    \]
    We know that $Ax = b$ is solvable $\Rightarrow \ b \in \mathcal{C}(A)$ 
    \begin{itemize}
        \item 1 \& 3: basic variables
        \item $\mathcal{C}(A) = $ the set of combinations of \( \begin{pmatrix}
            1 \\ 2 \\ -1
        \end{pmatrix} \) \& \( \begin{pmatrix}
            3 \\ 9 \\ 3
        \end{pmatrix} \) \\ 
        , which is also \( \left\{ \begin{pmatrix}
        b_1 \\ b_2 \\ b_3
        \end{pmatrix} \;\middle|\; b_3 - 2b_2 + 5b_1 = 0 \right\} \red{\perp \begin{pmatrix}
            5 \\ -2 \\ 1
        \end{pmatrix}} \)
    \end{itemize}
    
    \begin{eg}
    \[
    b = \begin{pmatrix}
        1 \\ 5 \\ 5
    \end{pmatrix}
    \]
    \end{eg}
    \[
    \begin{pmatrix}
        \redbox{1} & 3 & 3 & 2 \\
        0 & 0 & \redbox{3} & 1 \\
        0 & 0 & 0 & 0
    \end{pmatrix}\begin{pmatrix}
        u \\ v \\ w \\ y
    \end{pmatrix} = \begin{pmatrix}
        1 \\ 3 \\ 0
    \end{pmatrix} \quad \Longrightarrow \quad \begin{cases}
        w = 1 - \frac{1}{3}y \\
        u = -2 -3v -y
    \end{cases}
    \]
    \[
    x = \begin{pmatrix}
        u \\ v \\ w \\ y
    \end{pmatrix} = \begin{pmatrix}
        -2-3v-y \\ v \\ 1-\frac{1}{3}y \\ y
    \end{pmatrix} = \yel{\underset{\text{shift}}{\begin{pmatrix}
        -2 \\ 0 \\ 1 \\ 0
    \end{pmatrix}}} + \red{\underset{\text{solution to } Ax = 0 \text{ (nullspace)}}{v\begin{pmatrix}
        -3 \\ 1 \\ 0 \\ 0
    \end{pmatrix} + y \begin{pmatrix}
        -1 \\ 0 \\ -\frac{1}{3} \\ 1
    \end{pmatrix}}}
    \]
    \yel{Shift: particular solution to $Ax=b$ (set all free variables to be zero)}

    \[
        \Large \boxed{x_{\text{general}} = x_{\text{particular}} + x_{\text{homogeneous}}; \ x_g = x_p = x_h}
    \]
\end{itemize}

\newpage

Generally, the general solution is fills a two-dimensiona; surface (but NOT a subspace since it doesn't contain the zero vector (origin))

\vspace{1em}

It is paralled to the \blue{Nullspace of $A$}

\begin{center}
    \begin{tikzpicture}[>=Stealth, thick, scale=1.2]
        \coordinate (O) at (0,0);
        \draw[black, thick] (-2,0) -- (3,0) node[right, black] {nullspace of $A$};
        \draw[->, blue, thick] (O) -- (2,0) node[midway, below, blue] {$x_h$};
        \coordinate (Xp) at (0.7,1.5);
        \draw[->, green!70!black, thick] (O) -- (Xp) node[midway, left, green!70!black] {$x_p$};
        \node[above left, green!70!black] at (Xp) {$(Ax_p = b)$};
        \draw[yellow!80!orange, very thick] ($(Xp)+(-2,0)$) -- ($(Xp)+(3,0)$)
            node[right, yellow!50!black] {line of solutions of $Ax=b$};
        \coordinate (Xh) at (2,0);
        \coordinate (Xg) at ($(Xp)+(Xh)$);
        \fill[red] (Xg) circle(2pt);
        \node[above, red] at (Xg) {$x_g = x_p + x_h$ $(Ax_g = b)$};
        \draw[red, densely dotted] (Xh) -- (Xg);
        \filldraw[blue!50!black, fill=white] (O) circle(2pt) node[below left] {$O$};
    \end{tikzpicture}
\end{center}

\subsection{Steps to oobtain the solution to $Ax=b$}

\begin{enumerate}[label=(\roman*)]
    \item Reduce $Ax = b$ to $Ux = c$ \blue{to determine basic/free variables.}
    \item Set all free variables to zero \blue{to find particular solution, \(x_p\)}
    \item set RHS = 0. Give each free variables 1 others 0, in terms, find the hoomogeneous sloution, \blue{\(x_h\)}
    \[
    \Longrightarrow \quad x_g = x_p + x_h
    \]
\end{enumerate}

\begin{definition}[rank]
\bluebox{\blue{$A_{m\times n}$}} if there are $r$ pivots, there are \blue{$r$} basic variables and \blue{$n-r$} free variables. The number of pivots, $r$, is called the \redbox{rank} of the matrix.
\end{definition}

\begin{theorem}
    Suppose elimination reduce $A_{m \times } x = b$ to $Ux = c$ and there are $r$ pivots and the last \blue{$(m-r)$} rows of $U$ are zero. Then there is a solution only if last \blue{$(m-r)$} elements of $c$ are zeros.
    \begin{itemize}
        \item If $r = m$, there's always a solution. The general solution is the sum of particular solution and a homogeneous solution.
        \item If $r = n$, there are \blue{No} free variables and the null space contains \blue{$x = 0$ only}. The number $r$ is called the rank of $A$.
    \end{itemize} 
    Two extreme case: $A_{m\times n}x = b$
    \begin{enumerate}[label=(\arabic*)]
        \item If $r = n \ \rightarrow$ No free variables $\rightarrow \ \mathcal{N}(A) = \{x \in \mathbb{R}^n \;|\; Ax = 0\} = \blue{\{0\}}$ 
        \item If $r = m \ \rightarrow$ No zero rows in $U \ \rightarrow \ \mathcal{C}(A) = \blue{\mathbb{R}^m} \ \Rightarrow \ \exists \ \text{solution for all }b$
    \end{enumerate}
\end{theorem}

\section{Linear Independence, Basis and Dimension}

In the elimination process, we refer to the number, r, of pivots as the rank of $A$. This definition is purely computational rather than mathematical. We shall give a formal definition later.

Now we shall disscuss the following four ideas:
\begin{enumerate}[label=(\roman*)]
    \item linear independence or dependence
    \item \textbf{spanning} a subspace
    \item \textbf{basis} for a subspace
    \item \textbf{dimension} of a subspace
\end{enumerate}

\newpage

\begin{definition}
    Let $V$ be a vector space over $F$. A nonempty subset $S$ of $V$ is said to ve \redbox{linearly dependent} if there exist \red{distinct} vectors $v_1, v_2, \cdots, v_n$ in $S$ and scalar $\alpha_1, \alpha_2, \cdots, \alpha_n$ in $F$, not all of which are zero $\ni$
    \[
    \alpha_1 v_1 + \alpha_1 v_1 + \cdots + \alpha_n v_n = 0
    \]
    A set which is not linearly dependent is called linearly independent. If $S = \{v_1, v_2, \cdots, v_n\}$ then we say that $v_1, v_2, \cdots, v_n$ are linearly dependent/independent.
\end{definition}

